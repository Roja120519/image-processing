{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Processing in OpenCV\n",
    "- Color spaces\n",
    "- object tracking\n",
    "- how to find hsv values to track?\n",
    "- Image Thresholding\n",
    "- Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Colorspaces\n",
    "- syntax\n",
    "    - cv2.cvtColor(input_image, flag)\n",
    "    - flag means type of conversion\n",
    "\n",
    "- used to convert one image to another image \n",
    "- for example \n",
    "       - RGB<-->BGR\n",
    "       - RGB -->GRAY\n",
    "       - RGB<-->BGR -->GRAY\n",
    "       - RGB -->HSV\n",
    "       we have alot of color convergent modes\n",
    "- We have  274 Color convergent modes\n",
    "- Color image loaded by OpenCV is in BGR mode\n",
    "- Color image loadded by matplotlib as in RGB mode\n",
    "- So when we are displaying image in opencv to maplotlib their is slit changes are done.\n",
    "- Red pixels appear in blue color and vice versa\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.COLOR_BAYER_BG2BGR\n",
      "cv2.COLOR_BAYER_BG2BGRA\n",
      "cv2.COLOR_BAYER_BG2BGR_EA\n",
      "cv2.COLOR_BAYER_BG2BGR_VNG\n",
      "cv2.COLOR_BAYER_BG2GRAY\n",
      "cv2.COLOR_BAYER_BG2RGB\n",
      "cv2.COLOR_BAYER_BG2RGBA\n",
      "cv2.COLOR_BAYER_BG2RGB_EA\n",
      "cv2.COLOR_BAYER_BG2RGB_VNG\n",
      "cv2.COLOR_BAYER_GB2BGR\n",
      "cv2.COLOR_BAYER_GB2BGRA\n",
      "cv2.COLOR_BAYER_GB2BGR_EA\n",
      "cv2.COLOR_BAYER_GB2BGR_VNG\n",
      "cv2.COLOR_BAYER_GB2GRAY\n",
      "cv2.COLOR_BAYER_GB2RGB\n",
      "cv2.COLOR_BAYER_GB2RGBA\n",
      "cv2.COLOR_BAYER_GB2RGB_EA\n",
      "cv2.COLOR_BAYER_GB2RGB_VNG\n",
      "cv2.COLOR_BAYER_GR2BGR\n",
      "cv2.COLOR_BAYER_GR2BGRA\n",
      "cv2.COLOR_BAYER_GR2BGR_EA\n",
      "cv2.COLOR_BAYER_GR2BGR_VNG\n",
      "cv2.COLOR_BAYER_GR2GRAY\n",
      "cv2.COLOR_BAYER_GR2RGB\n",
      "cv2.COLOR_BAYER_GR2RGBA\n",
      "cv2.COLOR_BAYER_GR2RGB_EA\n",
      "cv2.COLOR_BAYER_GR2RGB_VNG\n",
      "cv2.COLOR_BAYER_RG2BGR\n",
      "cv2.COLOR_BAYER_RG2BGRA\n",
      "cv2.COLOR_BAYER_RG2BGR_EA\n",
      "cv2.COLOR_BAYER_RG2BGR_VNG\n",
      "cv2.COLOR_BAYER_RG2GRAY\n",
      "cv2.COLOR_BAYER_RG2RGB\n",
      "cv2.COLOR_BAYER_RG2RGBA\n",
      "cv2.COLOR_BAYER_RG2RGB_EA\n",
      "cv2.COLOR_BAYER_RG2RGB_VNG\n",
      "cv2.COLOR_BGR2BGR555\n",
      "cv2.COLOR_BGR2BGR565\n",
      "cv2.COLOR_BGR2BGRA\n",
      "cv2.COLOR_BGR2GRAY\n",
      "cv2.COLOR_BGR2HLS\n",
      "cv2.COLOR_BGR2HLS_FULL\n",
      "cv2.COLOR_BGR2HSV\n",
      "cv2.COLOR_BGR2HSV_FULL\n",
      "cv2.COLOR_BGR2LAB\n",
      "cv2.COLOR_BGR2LUV\n",
      "cv2.COLOR_BGR2Lab\n",
      "cv2.COLOR_BGR2Luv\n",
      "cv2.COLOR_BGR2RGB\n",
      "cv2.COLOR_BGR2RGBA\n",
      "cv2.COLOR_BGR2XYZ\n",
      "cv2.COLOR_BGR2YCR_CB\n",
      "cv2.COLOR_BGR2YCrCb\n",
      "cv2.COLOR_BGR2YUV\n",
      "cv2.COLOR_BGR2YUV_I420\n",
      "cv2.COLOR_BGR2YUV_IYUV\n",
      "cv2.COLOR_BGR2YUV_YV12\n",
      "cv2.COLOR_BGR5552BGR\n",
      "cv2.COLOR_BGR5552BGRA\n",
      "cv2.COLOR_BGR5552GRAY\n",
      "cv2.COLOR_BGR5552RGB\n",
      "cv2.COLOR_BGR5552RGBA\n",
      "cv2.COLOR_BGR5652BGR\n",
      "cv2.COLOR_BGR5652BGRA\n",
      "cv2.COLOR_BGR5652GRAY\n",
      "cv2.COLOR_BGR5652RGB\n",
      "cv2.COLOR_BGR5652RGBA\n",
      "cv2.COLOR_BGRA2BGR\n",
      "cv2.COLOR_BGRA2BGR555\n",
      "cv2.COLOR_BGRA2BGR565\n",
      "cv2.COLOR_BGRA2GRAY\n",
      "cv2.COLOR_BGRA2RGB\n",
      "cv2.COLOR_BGRA2RGBA\n",
      "cv2.COLOR_BGRA2YUV_I420\n",
      "cv2.COLOR_BGRA2YUV_IYUV\n",
      "cv2.COLOR_BGRA2YUV_YV12\n",
      "cv2.COLOR_BayerBG2BGR\n",
      "cv2.COLOR_BayerBG2BGRA\n",
      "cv2.COLOR_BayerBG2BGR_EA\n",
      "cv2.COLOR_BayerBG2BGR_VNG\n",
      "cv2.COLOR_BayerBG2GRAY\n",
      "cv2.COLOR_BayerBG2RGB\n",
      "cv2.COLOR_BayerBG2RGBA\n",
      "cv2.COLOR_BayerBG2RGB_EA\n",
      "cv2.COLOR_BayerBG2RGB_VNG\n",
      "cv2.COLOR_BayerGB2BGR\n",
      "cv2.COLOR_BayerGB2BGRA\n",
      "cv2.COLOR_BayerGB2BGR_EA\n",
      "cv2.COLOR_BayerGB2BGR_VNG\n",
      "cv2.COLOR_BayerGB2GRAY\n",
      "cv2.COLOR_BayerGB2RGB\n",
      "cv2.COLOR_BayerGB2RGBA\n",
      "cv2.COLOR_BayerGB2RGB_EA\n",
      "cv2.COLOR_BayerGB2RGB_VNG\n",
      "cv2.COLOR_BayerGR2BGR\n",
      "cv2.COLOR_BayerGR2BGRA\n",
      "cv2.COLOR_BayerGR2BGR_EA\n",
      "cv2.COLOR_BayerGR2BGR_VNG\n",
      "cv2.COLOR_BayerGR2GRAY\n",
      "cv2.COLOR_BayerGR2RGB\n",
      "cv2.COLOR_BayerGR2RGBA\n",
      "cv2.COLOR_BayerGR2RGB_EA\n",
      "cv2.COLOR_BayerGR2RGB_VNG\n",
      "cv2.COLOR_BayerRG2BGR\n",
      "cv2.COLOR_BayerRG2BGRA\n",
      "cv2.COLOR_BayerRG2BGR_EA\n",
      "cv2.COLOR_BayerRG2BGR_VNG\n",
      "cv2.COLOR_BayerRG2GRAY\n",
      "cv2.COLOR_BayerRG2RGB\n",
      "cv2.COLOR_BayerRG2RGBA\n",
      "cv2.COLOR_BayerRG2RGB_EA\n",
      "cv2.COLOR_BayerRG2RGB_VNG\n",
      "cv2.COLOR_COLORCVT_MAX\n",
      "cv2.COLOR_GRAY2BGR\n",
      "cv2.COLOR_GRAY2BGR555\n",
      "cv2.COLOR_GRAY2BGR565\n",
      "cv2.COLOR_GRAY2BGRA\n",
      "cv2.COLOR_GRAY2RGB\n",
      "cv2.COLOR_GRAY2RGBA\n",
      "cv2.COLOR_HLS2BGR\n",
      "cv2.COLOR_HLS2BGR_FULL\n",
      "cv2.COLOR_HLS2RGB\n",
      "cv2.COLOR_HLS2RGB_FULL\n",
      "cv2.COLOR_HSV2BGR\n",
      "cv2.COLOR_HSV2BGR_FULL\n",
      "cv2.COLOR_HSV2RGB\n",
      "cv2.COLOR_HSV2RGB_FULL\n",
      "cv2.COLOR_LAB2BGR\n",
      "cv2.COLOR_LAB2LBGR\n",
      "cv2.COLOR_LAB2LRGB\n",
      "cv2.COLOR_LAB2RGB\n",
      "cv2.COLOR_LBGR2LAB\n",
      "cv2.COLOR_LBGR2LUV\n",
      "cv2.COLOR_LBGR2Lab\n",
      "cv2.COLOR_LBGR2Luv\n",
      "cv2.COLOR_LRGB2LAB\n",
      "cv2.COLOR_LRGB2LUV\n",
      "cv2.COLOR_LRGB2Lab\n",
      "cv2.COLOR_LRGB2Luv\n",
      "cv2.COLOR_LUV2BGR\n",
      "cv2.COLOR_LUV2LBGR\n",
      "cv2.COLOR_LUV2LRGB\n",
      "cv2.COLOR_LUV2RGB\n",
      "cv2.COLOR_Lab2BGR\n",
      "cv2.COLOR_Lab2LBGR\n",
      "cv2.COLOR_Lab2LRGB\n",
      "cv2.COLOR_Lab2RGB\n",
      "cv2.COLOR_Luv2BGR\n",
      "cv2.COLOR_Luv2LBGR\n",
      "cv2.COLOR_Luv2LRGB\n",
      "cv2.COLOR_Luv2RGB\n",
      "cv2.COLOR_M_RGBA2RGBA\n",
      "cv2.COLOR_RGB2BGR\n",
      "cv2.COLOR_RGB2BGR555\n",
      "cv2.COLOR_RGB2BGR565\n",
      "cv2.COLOR_RGB2BGRA\n",
      "cv2.COLOR_RGB2GRAY\n",
      "cv2.COLOR_RGB2HLS\n",
      "cv2.COLOR_RGB2HLS_FULL\n",
      "cv2.COLOR_RGB2HSV\n",
      "cv2.COLOR_RGB2HSV_FULL\n",
      "cv2.COLOR_RGB2LAB\n",
      "cv2.COLOR_RGB2LUV\n",
      "cv2.COLOR_RGB2Lab\n",
      "cv2.COLOR_RGB2Luv\n",
      "cv2.COLOR_RGB2RGBA\n",
      "cv2.COLOR_RGB2XYZ\n",
      "cv2.COLOR_RGB2YCR_CB\n",
      "cv2.COLOR_RGB2YCrCb\n",
      "cv2.COLOR_RGB2YUV\n",
      "cv2.COLOR_RGB2YUV_I420\n",
      "cv2.COLOR_RGB2YUV_IYUV\n",
      "cv2.COLOR_RGB2YUV_YV12\n",
      "cv2.COLOR_RGBA2BGR\n",
      "cv2.COLOR_RGBA2BGR555\n",
      "cv2.COLOR_RGBA2BGR565\n",
      "cv2.COLOR_RGBA2BGRA\n",
      "cv2.COLOR_RGBA2GRAY\n",
      "cv2.COLOR_RGBA2M_RGBA\n",
      "cv2.COLOR_RGBA2RGB\n",
      "cv2.COLOR_RGBA2YUV_I420\n",
      "cv2.COLOR_RGBA2YUV_IYUV\n",
      "cv2.COLOR_RGBA2YUV_YV12\n",
      "cv2.COLOR_RGBA2mRGBA\n",
      "cv2.COLOR_XYZ2BGR\n",
      "cv2.COLOR_XYZ2RGB\n",
      "cv2.COLOR_YCR_CB2BGR\n",
      "cv2.COLOR_YCR_CB2RGB\n",
      "cv2.COLOR_YCrCb2BGR\n",
      "cv2.COLOR_YCrCb2RGB\n",
      "cv2.COLOR_YUV2BGR\n",
      "cv2.COLOR_YUV2BGRA_I420\n",
      "cv2.COLOR_YUV2BGRA_IYUV\n",
      "cv2.COLOR_YUV2BGRA_NV12\n",
      "cv2.COLOR_YUV2BGRA_NV21\n",
      "cv2.COLOR_YUV2BGRA_UYNV\n",
      "cv2.COLOR_YUV2BGRA_UYVY\n",
      "cv2.COLOR_YUV2BGRA_Y422\n",
      "cv2.COLOR_YUV2BGRA_YUNV\n",
      "cv2.COLOR_YUV2BGRA_YUY2\n",
      "cv2.COLOR_YUV2BGRA_YUYV\n",
      "cv2.COLOR_YUV2BGRA_YV12\n",
      "cv2.COLOR_YUV2BGRA_YVYU\n",
      "cv2.COLOR_YUV2BGR_I420\n",
      "cv2.COLOR_YUV2BGR_IYUV\n",
      "cv2.COLOR_YUV2BGR_NV12\n",
      "cv2.COLOR_YUV2BGR_NV21\n",
      "cv2.COLOR_YUV2BGR_UYNV\n",
      "cv2.COLOR_YUV2BGR_UYVY\n",
      "cv2.COLOR_YUV2BGR_Y422\n",
      "cv2.COLOR_YUV2BGR_YUNV\n",
      "cv2.COLOR_YUV2BGR_YUY2\n",
      "cv2.COLOR_YUV2BGR_YUYV\n",
      "cv2.COLOR_YUV2BGR_YV12\n",
      "cv2.COLOR_YUV2BGR_YVYU\n",
      "cv2.COLOR_YUV2GRAY_420\n",
      "cv2.COLOR_YUV2GRAY_I420\n",
      "cv2.COLOR_YUV2GRAY_IYUV\n",
      "cv2.COLOR_YUV2GRAY_NV12\n",
      "cv2.COLOR_YUV2GRAY_NV21\n",
      "cv2.COLOR_YUV2GRAY_UYNV\n",
      "cv2.COLOR_YUV2GRAY_UYVY\n",
      "cv2.COLOR_YUV2GRAY_Y422\n",
      "cv2.COLOR_YUV2GRAY_YUNV\n",
      "cv2.COLOR_YUV2GRAY_YUY2\n",
      "cv2.COLOR_YUV2GRAY_YUYV\n",
      "cv2.COLOR_YUV2GRAY_YV12\n",
      "cv2.COLOR_YUV2GRAY_YVYU\n",
      "cv2.COLOR_YUV2RGB\n",
      "cv2.COLOR_YUV2RGBA_I420\n",
      "cv2.COLOR_YUV2RGBA_IYUV\n",
      "cv2.COLOR_YUV2RGBA_NV12\n",
      "cv2.COLOR_YUV2RGBA_NV21\n",
      "cv2.COLOR_YUV2RGBA_UYNV\n",
      "cv2.COLOR_YUV2RGBA_UYVY\n",
      "cv2.COLOR_YUV2RGBA_Y422\n",
      "cv2.COLOR_YUV2RGBA_YUNV\n",
      "cv2.COLOR_YUV2RGBA_YUY2\n",
      "cv2.COLOR_YUV2RGBA_YUYV\n",
      "cv2.COLOR_YUV2RGBA_YV12\n",
      "cv2.COLOR_YUV2RGBA_YVYU\n",
      "cv2.COLOR_YUV2RGB_I420\n",
      "cv2.COLOR_YUV2RGB_IYUV\n",
      "cv2.COLOR_YUV2RGB_NV12\n",
      "cv2.COLOR_YUV2RGB_NV21\n",
      "cv2.COLOR_YUV2RGB_UYNV\n",
      "cv2.COLOR_YUV2RGB_UYVY\n",
      "cv2.COLOR_YUV2RGB_Y422\n",
      "cv2.COLOR_YUV2RGB_YUNV\n",
      "cv2.COLOR_YUV2RGB_YUY2\n",
      "cv2.COLOR_YUV2RGB_YUYV\n",
      "cv2.COLOR_YUV2RGB_YV12\n",
      "cv2.COLOR_YUV2RGB_YVYU\n",
      "cv2.COLOR_YUV420P2BGR\n",
      "cv2.COLOR_YUV420P2BGRA\n",
      "cv2.COLOR_YUV420P2GRAY\n",
      "cv2.COLOR_YUV420P2RGB\n",
      "cv2.COLOR_YUV420P2RGBA\n",
      "cv2.COLOR_YUV420SP2BGR\n",
      "cv2.COLOR_YUV420SP2BGRA\n",
      "cv2.COLOR_YUV420SP2GRAY\n",
      "cv2.COLOR_YUV420SP2RGB\n",
      "cv2.COLOR_YUV420SP2RGBA\n",
      "cv2.COLOR_YUV420p2BGR\n",
      "cv2.COLOR_YUV420p2BGRA\n",
      "cv2.COLOR_YUV420p2GRAY\n",
      "cv2.COLOR_YUV420p2RGB\n",
      "cv2.COLOR_YUV420p2RGBA\n",
      "cv2.COLOR_YUV420sp2BGR\n",
      "cv2.COLOR_YUV420sp2BGRA\n",
      "cv2.COLOR_YUV420sp2GRAY\n",
      "cv2.COLOR_YUV420sp2RGB\n",
      "cv2.COLOR_YUV420sp2RGBA\n",
      "cv2.COLOR_mRGBA2RGBA\n",
      "\n",
      "\n",
      "We have  274 Color convergent modes\n"
     ]
    }
   ],
   "source": [
    "# To print color convergent models avaialble in openCV and count them\n",
    "\n",
    "import cv2\n",
    "count=0\n",
    "for i in dir(cv2):\n",
    "    if i.startswith(\"COLOR_\"):\n",
    "        print(\"cv2.\",end=\"\")\n",
    "        print(i)\n",
    "        count+=1\n",
    "print(\"\\n\\nWe have \", count,\"Color convergent modes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert one mode to another one color convergent models\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img=cv2.imread(\"standard_test_images\\\\standard_test_images\\\\1.tiff\")\n",
    "\n",
    "BGR=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "GRAY=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "LUV=cv2.cvtColor(BGR,cv2.COLOR_BGR2LUV)\n",
    "LBGR=cv2.cvtColor(LUV,cv2.COLOR_LUV2LBGR)\n",
    "LAB=cv2.cvtColor(BGR,cv2.COLOR_BGR2LAB)\n",
    "RGBA=cv2.cvtColor(BGR,cv2.COLOR_BGR2RGBA)\n",
    "HSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "names=[BGR,GRAY,LUV,LBGR,LAB,RGBA,HSV]\n",
    "title=[\"BGR\",\"GRAY\",\"LUV\",\"LBGR\",\"LAB\",\"RGBA\",\"HSV\"]\n",
    "for i in range(0,len(names),1):\n",
    "    cv2.imshow(title[i],names[i])\n",
    "    plt.subplot(2,8,i+1)\n",
    "    plt.imshow(names[i]),plt.title(title[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Tracking\n",
    "\n",
    "- In this we will try to extract a blue colored objects\n",
    "- Take a frame in video or an image\n",
    "- Convert from BGR to HSV color-space\n",
    "- We threshold the HSV image for a range of blue color\n",
    "- Now extract the blue object alone, we can do whatever on that image we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"standard_test_images\\\\standard_test_images\\\\1.tiff\")\n",
    "hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_blue = np.array([110,50,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "\n",
    "lower_red = np.array([0,0,255])\n",
    "upper_red = np.array([85,85,255])\n",
    "\n",
    "mask=cv2.inRange(hsv,lower_blue,upper_blue)\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "\n",
    "cv2.imshow(\"hsv\",hsv)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"mask\",mask)\n",
    "cv2.imshow(\"res\",res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video\n",
    "\n",
    "capture=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=capture.read()\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    lower_blue=np.array([110,50,50])\n",
    "    upper_blue=np.array([130,255,255])\n",
    "    mask=cv2.inRange(hsv,lower_blue,upper_blue)\n",
    "    res=cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    cv2.imshow(\"mask\",mask)\n",
    "    cv2.imshow(\"res\",res)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to find HSV values to track?\n",
    "- we can do this by using cv2.cvtColor function\n",
    "- Instead of passing an image, you just pass the BGR values you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "red=np.uint8([[[0,0,255]]])\n",
    "hsv_value_red=cv2.cvtColor(red,cv2.COLOR_BGR2HSV)\n",
    "print(hsv_value_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 60 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "green = np.uint8([[[0,255,0 ]]])\n",
    "hsv_green = cv2.cvtColor(green,cv2.COLOR_BGR2HSV)\n",
    "print(hsv_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[120 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "blue=np.uint8([[[255,0,0]]])\n",
    "hsv_blue=cv2.cvtColor(blue,cv2.COLOR_BGR2HSV)\n",
    "print(hsv_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Thresholding\n",
    "- Simple Thresholding\n",
    "    - If pixel value is greater than a threshold value, it is assigned one value (may be white), else it is assigned another value(black)\n",
    "    - The function used is cv2.threshold\n",
    "    - input\n",
    "        - source image, which should be a grayscale image\n",
    "        - Second argument is the threshold value which is used to classify the pixel values\n",
    "        - Third argument is the maxVal \n",
    "        - different styles of thresholding we will use one as fourth argument\n",
    "\n",
    "- cv2.THRESH_BINARY\n",
    "- cv2.THRESH_BINARY_INV\n",
    "- cv2.THRESH_TRUNC\n",
    "- cv2.THRESH_TOZERO\n",
    "- cv2.THRESH_TOZERO_INV\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(\"standard_test_images\\\\standard_test_images\\\\gray.tiff\")\n",
    "ret,binary=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,binary_inv=cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,trunc=cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,tozero=cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,tozero_inv=cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "names=[img,binary,binary_inv,trunc,tozero,tozero_inv]\n",
    "titles=['img','binary','binary_inv','trunc','tozero','tozero_inv']\n",
    "for i in range(0,len(names),1):\n",
    "    #cv2.imshow(titles[i],names[i])\n",
    "    plt.subplot(2,6,i+1)\n",
    "    plt.imshow(names[i]),plt.title(titles[i])\n",
    "    #if cv2.waitKey(1)==27:\n",
    "     #   break\n",
    "#cv2.destroyAllWindows()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Thresholding\n",
    "\n",
    "- in previous one we used a global value as threshold value\n",
    "- But it may not be good in all the conditions where image has different lighting conditions in different areas.\n",
    "- So we will use adaptive thresholding\n",
    "- algorithm calculate the threshold for a small regions of the image. \n",
    "- So we get different thresholds for different regions of the same image and it gives us better results for images with varying illumination.\n",
    "\n",
    "- Adaptive Method - It decides how thresholding value is calculated.\n",
    "\n",
    "- cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
    "- cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
    "- Block Size -> It decides the size of neighbourhood area.\n",
    "\n",
    "- C -> It is just a constant which is subtracted from the mean or weighted mean calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"standard_test_images\\\\standard_test_images\\\\gray.tiff\",0)\n",
    "img=cv2.medianBlur(img,5)\n",
    "mean=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "gaus=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,13,2)\n",
    "\n",
    "cv2.imshow('mean',mean)\n",
    "cv2.imshow('gaus',gaus)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052676"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1026 * 1026\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"standard_test_images\\\\standard_test_images\\\\gray.tiff\",0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "#ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,150,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,13,2)\n",
    "cv2.imshow(\"th2\",th2)\n",
    "cv2.imshow(\"th3\",th3)\n",
    "#plt.imshow(th3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
